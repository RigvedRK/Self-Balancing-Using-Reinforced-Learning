{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from robot import Robot\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the robot interface gym environment\n",
    "robot=Robot()\n",
    "\n",
    "# validate that the robot interface is valid\n",
    "check_env(robot, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the robot interface\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = robot.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        robot.render()\n",
    "        action = robot.action_space.sample()\n",
    "        n_state, reward, done, info = robot.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "robot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "\n",
    "class CustomPolicy(FeedForwardPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomPolicy, self).__init__(*args, **kwargs,\n",
    "                                           net_arch=[dict(pi=[2],\n",
    "                                                          vf=[2])],\n",
    "                                           feature_extraction=\"mlp\")\n",
    "                                           \n",
    "register_policy('CustomPolicy', CustomPolicy)\n",
    "log_path = os.path.join(os.path, 'logs')\n",
    "model = PPO(policy='CustomPolicy', env=robot, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "model.learn(total_timesteps=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('PPO')\n",
    "evaluate_policy(model, robot, n_eval_episodes=10, render=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
